{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM classifier in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SpatialDropout1D, Dense, Flatten, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint # new! \n",
    "import os # new! \n",
    "from sklearn.metrics import roc_auc_score, roc_curve # new!\n",
    "import matplotlib.pyplot as plt # new!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/lstm'\n",
    "\n",
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64\n",
    "n_unique_words = 10000\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "# neural network architecture: \n",
    "n_lstm = 256\n",
    "droput_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given data set: \n",
    "\n",
    "* the Keras text utilities [here](https://keras.io/preprocessing/text/) quickly preprocess natural language and convert it into an index\n",
    "* the `keras.preprocessing.text.Tokenizer` class may do everything you need in one line:\n",
    "    * tokenize into words or characters\n",
    "    * `num_words`: maximum unique tokens\n",
    "    * filter out punctuation\n",
    "    * lower case\n",
    "    * convert words to an integer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,   33,    6,   22,   12,  215,   28,   77,   52,    5,   14,\n",
       "         407,   16,   82,    2,    8,    4,  107,  117, 5952,   15,  256,\n",
       "           4,    2,    7, 3766,    5,  723,   36,   71,   43,  530,  476,\n",
       "          26,  400,  317,   46,    7,    4,    2, 1029,   13,  104,   88,\n",
       "           4,  381,   15,  297,   98,   32, 2071,   56,   26,  141,    6,\n",
       "         194, 7486,   18,    4,  226,   22,   21,  134,  476,   26,  480,\n",
       "           5,  144,   30, 5535,   18,   51,   36,   28,  224,   92,   25,\n",
       "         104,    4,  226,   65,   16,   38, 1334,   88,   12,   16,  283,\n",
       "           5,   16, 4472,  113,  103,   32,   15,   16, 5345,   19,  178,\n",
       "          32],\n",
       "       [ 163,   11, 3215,    2,    4, 1153,    9,  194,  775,    7, 8255,\n",
       "           2,  349, 2637,  148,  605,    2, 8003,   15,  123,  125,   68,\n",
       "           2, 6853,   15,  349,  165, 4362,   98,    5,    4,  228,    9,\n",
       "          43,    2, 1157,   15,  299,  120,    5,  120,  174,   11,  220,\n",
       "         175,  136,   50,    9, 4373,  228, 8255,    5,    2,  656,  245,\n",
       "        2350,    5,    4, 9837,  131,  152,  491,   18,    2,   32, 7464,\n",
       "        1212,   14,    9,    6,  371,   78,   22,  625,   64, 1382,    9,\n",
       "           8,  168,  145,   23,    4, 1690,   15,   16,    4, 1355,    5,\n",
       "          28,    6,   52,  154,  462,   33,   89,   78,  285,   16,  145,\n",
       "          95],\n",
       "       [1301,    4, 1873,   33,   89,   78,   12,   66,   16,    4,  360,\n",
       "           7,    4,   58,  316,  334,   11,    4, 1716,   43,  645,  662,\n",
       "           8,  257,   85, 1200,   42, 1228, 2578,   83,   68, 3912,   15,\n",
       "          36,  165, 1539,  278,   36,   69,    2,  780,    8,  106,   14,\n",
       "        6905, 1338,   18,    6,   22,   12,  215,   28,  610,   40,    6,\n",
       "          87,  326,   23, 2300,   21,   23,   22,   12,  272,   40,   57,\n",
       "          31,   11,    4,   22,   47,    6, 2307,   51,    9,  170,   23,\n",
       "         595,  116,  595, 1352,   13,  191,   79,  638,   89,    2,   14,\n",
       "           9,    8,  106,  607,  624,   35,  534,    6,  227,    7,  129,\n",
       "         113],\n",
       "       [  40,    2,   13,  188, 1076, 3222,   19,    4,    2,    7, 2348,\n",
       "         537,   23,   53,  537,   21,   82,   40,    2,   13,    2,   14,\n",
       "         280,   13,  219,    4,    2,  431,  758,  859,    4,  953, 1052,\n",
       "           2,    7, 5991,    5,   94,   40,   25,  238,   60,    2,    4,\n",
       "           2,  804,    2,    7,    4, 9941,  132,    8,   67,    6,   22,\n",
       "          15,    9,  283,    8, 5168,   14,   31,    9,  242,  955,   48,\n",
       "          25,  279,    2,   23,   12, 1685,  195,   25,  238,   60,  796,\n",
       "           2,    4,  671,    7, 2804,    5,    4,  559,  154,  888,    7,\n",
       "         726,   50,   26,   49, 7008,   15,  566,   30,  579,   21,   64,\n",
       "        2574],\n",
       "       [  13,   16,  131, 2073,  249,  114,  249,  229,  249,   20,   13,\n",
       "          28,  126,  110,   13,  473,    8,  569,   61,  419,   56,  429,\n",
       "           6, 1513,   18,   35,  534,   95,  474,  570,    5,   25,  124,\n",
       "         138,   88,   12,  421, 1543,   52,  725, 6397,   61,  419,   11,\n",
       "          13, 1571,   15, 1543,   20,   11,    4,    2,    5,  296,   12,\n",
       "        3524,    5,   15,  421,  128,   74,  233,  334,  207,  126,  224,\n",
       "          12,  562,  298, 2167, 1272,    7, 2601,    5,  516,  988,   43,\n",
       "           8,   79,  120,   15,  595,   13,  784,   25, 3171,   18,  165,\n",
       "         170,  143,   19,   14,    5, 7224,    6,  226,  251,    7,   61,\n",
       "         113],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    1,  778,  128,   74,   12,  630,  163,   15,    4,\n",
       "        1766, 7982, 1051,    2,   32,   85,  156,   45,   40,  148,  139,\n",
       "         121,  664,  665,   10,   10, 1361,  173,    4,  749,    2,   16,\n",
       "        3804,    8,    4,  226,   65,   12,   43,  127,   24,    2,   10,\n",
       "          10]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print len(x_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "# model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "# model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(Dense(n_dense, activation='relu'))\n",
    "# model.add(Dropout(dropout))\n",
    "model.add(LSTM(n_lstm, dropout=droput_lstm))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               328704    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 968,961\n",
      "Trainable params: 968,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10000, 640000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim, n_unique_words, n_dim * n_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64, 6400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_review_length, n_dim, n_dim * max_review_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "11008/25000 [============>.................] - ETA: 1:11 - loss: 0.6578 - acc: 0.6160"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, \n",
    "          verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.03.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
